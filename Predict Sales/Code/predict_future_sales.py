# -*- coding: utf-8 -*-
"""Predict_Future_Sales.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NXQPuvY29zdKvR6XklCR6LNkH8-lXeFG

In this project I worked with a challenging time-series dataset consisting of daily sales data provided by one of the largest Russian software firms - 1C Company. 

Goal : To predict total sales for every product and store in the next month.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv("/content/drive/My Drive/sales_train.csv")
dataset.head()

shops = pd.read_csv('shops.csv')
items = pd.read_csv('items.csv')
item_categories = pd.read_csv('item_categories.csv')

test = pd.read_csv('test.csv')
print(test.head())

dfm = dataset.groupby(['date_block_num'], as_index=False )['item_cnt_day'].sum()
dfm.head()
dfm.plot()

"""We can see that as the time progresses the item count drops.

Removing the outliers
"""

plt.figure(figsize=(10,4))
plt.xlim(100, 3000)
sns.boxplot(x=dataset.item_cnt_day)

plt.figure(figsize=(10,4))
plt.xlim(dataset.item_price.min(), dataset.item_price.max()*1.1)
sns.boxplot(x=dataset.item_price)

dataset = dataset[dataset.item_price<100000]
dataset = dataset[dataset.item_cnt_day<1001]

median = dataset[(dataset.shop_id==32)&(dataset.item_id==2973)&(dataset.date_block_num==4)&(dataset.item_price>0)].item_price.median()
dataset.loc[dataset.item_price<0, 'item_price'] = median
dataset.loc[dataset.item_cnt_day<0, 'item_cnt_day'] = 1

from itertools import product
matrix = []
cols = ['date_block_num','shop_id','item_id']
for i in range(0,34):
  month = dataset[dataset.date_block_num == i]
  matrix.append(np.array(list(product([i], month.shop_id.unique(), month.item_id.unique())), dtype='int16'))

matrix = pd.DataFrame(np.vstack(matrix), columns=cols)
matrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)
matrix['shop_id'] = matrix['shop_id'].astype(np.int8)
matrix['item_id'] = matrix['item_id'].astype(np.int16)
matrix.sort_values(cols,inplace=True)
matrix.head()

dataset['revenue'] = dataset['item_price'] * dataset['item_cnt_day']

dataset.head()

"""Add the item count per month feature"""

group = dataset.groupby(['date_block_num','shop_id','item_id']).agg({'item_cnt_day': ['sum']})
group.columns = ['item_cnt_month']
group.reset_index(inplace=True)
print(group)
matrix = pd.merge(matrix, group, on=cols, how='left')
matrix['item_cnt_month'] = (matrix['item_cnt_month']
                                .fillna(0)
                                .clip(0,20)
                                .astype(np.float16))

matrix.head()

"""Append test pairs to the matrix"""

test['date_block_num'] = 34
test['date_block_num'] = test['date_block_num'].astype(np.int8)
test['shop_id'] = test['shop_id'].astype(np.int8)
test['item_id'] = test['item_id'].astype(np.int16)
print(test.head())

matrix = pd.concat([matrix , test], keys=cols, ignore_index=True, sort=False)
matrix.fillna(0, inplace=True)

matrix.head()

"""Add lag features"""

def lag_feature(df, lags, col):
    tmp = df[['date_block_num','shop_id','item_id',col]]
    for i in lags:
        shifted = tmp.copy()
        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]
        shifted['date_block_num'] += i
        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')
    return df

matrix = lag_feature(matrix, [1,2,3], 'item_cnt_month')

matrix.head()

"""Add average item cnt for each month"""

group = matrix.groupby('date_block_num').agg({'item_cnt_month' : ['mean']})
group.columns = ['date_avg_item_cnt']
group.reset_index(inplace=True)

matrix = pd.merge(matrix, group, on='date_block_num', how='left')
matrix['date_avg_item_cnt'] = matrix['date_avg_item_cnt'].astype(np.float16)
matrix = lag_feature(matrix, [1,2,3], 'date_avg_item_cnt')
matrix.drop('date_avg_item_cnt', inplace=True, axis=1)

"""Add the average item count for each item in a month"""

group = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month' : ['mean']})
group.columns = ['date_item_avg_item_cnt']
group.reset_index(inplace=True)

matrix = pd.merge(matrix, group, on=['date_block_num', 'item_id'], how='left')
matrix['date_item_avg_item_cnt'] = matrix['date_item_avg_item_cnt'].astype(np.float16)
matrix = lag_feature(matrix, [1,2,3], 'date_item_avg_item_cnt')
matrix.drop('date_item_avg_item_cnt', inplace=True, axis=1)

"""Add the average item count for each shop in a month"""

group = matrix.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month' : ['mean']})
group.columns = ['date_shop_avg_item_cnt']
group.reset_index(inplace=True)

matrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id'], how='left')
matrix['date_shop_avg_item_cnt'] = matrix['date_shop_avg_item_cnt'].astype(np.float16)
matrix = lag_feature(matrix, [1,2,3], 'date_shop_avg_item_cnt')
matrix.drop('date_shop_avg_item_cnt', inplace=True, axis=1)

"""Add the price and revenue for each item"""

group = dataset[['date_block_num', 'shop_id', 'item_id', 'item_price', 'revenue']]
matrix = pd.merge(matrix, group, how='left', on=cols)
matrix.columns

"""Add month, date features"""

matrix['month'] = matrix['date_block_num'] % 12

days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])
matrix['days'] = matrix['month'].map(days).astype(np.int8)

matrix = matrix[matrix.date_block_num > 11]

"""Fill all the null values"""

matrix.fillna(0, inplace=True)

matrix.info()

"""Split the data into training, val and test set"""

X_train = matrix[matrix['date_block_num'] < 33].drop('item_cnt_month', axis=1)
Y_train = matrix[matrix['date_block_num'] < 33]['item_cnt_month']
X_valid = matrix[matrix.date_block_num == 33].drop(['item_cnt_month'], axis=1)
Y_valid = matrix[matrix.date_block_num == 33]['item_cnt_month']
X_test = matrix[matrix.date_block_num == 34].drop(['item_cnt_month'], axis=1)

X_train_series = X_train.values.reshape((X_train.shape[0], X_train.shape[1], 1))
X_valid_series = X_valid.values.reshape((X_valid.shape[0], X_valid.shape[1], 1))
print('Train set shape', X_train_series.shape)
print('Validation set shape', X_valid_series.shape)

"""Building your LSTM model"""

from tensorflow.keras.optimizers import Adam
epochs = 40
batch = 256
lr = 0.0003
adam = Adam(lr)

from tensorflow import keras
from keras.models import Sequential

model_lstm = Sequential()
model_lstm.add(keras.layers.LSTM(24, activation='relu', input_shape=(X_train_series.shape[1], X_train_series.shape[2])))
model_lstm.add(keras.layers.Dense(1))
model_lstm.compile(loss='mse', optimizer=adam)
model_lstm.summary()

lstm_history = model_lstm.fit(X_train_series, Y_train, validation_data=(X_valid_series, Y_valid), epochs=10, verbose=2)

from xgboost import XGBRegressor
model = XGBRegressor(
    max_depth=8,
    n_estimators=1000,
    min_child_weight=300, 
    colsample_bytree=0.8, 
    subsample=0.8, 
    eta=0.3,    
    seed=42)

model.fit(
    X_train, 
    Y_train, 
    eval_metric="rmse", 
    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], 
    verbose=2, 
    early_stopping_rounds = 10)

X_test_series = X_test.values.reshape((X_test.shape[0], X_test.shape[1], 1))
X_valid_series = X_valid.values.reshape((X_valid.shape[0], X_valid.shape[1], 1))

Y_pred = model_lstm.predict(X_valid_series).clip(0, 20)
Y_test = model_lstm.predict(X_test_series).clip(0, 20)

from sklearn.metrics import r2_score
print(r2_score(Y_valid, Y_pred))

print(Y_test.shape)

submission = pd.DataFrame({
    "ID": test.index, 
    "item_cnt_month": Y_test.flatten()
})
submission.to_csv('xgb_submission.csv', index=False)

from xgboost import plot_importance

def plot_features(booster, figsize):    
    fig, ax = plt.subplots(1,1,figsize=figsize)
    return plot_importance(booster=booster, ax=ax)